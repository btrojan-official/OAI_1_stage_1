{"cells":[{"cell_type":"markdown","metadata":{"id":"sMnVD7zdX92T"},"source":["# Ataki adwersarialne"]},{"cell_type":"markdown","metadata":{"id":"pqcmfMYuX92V"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"nvufw7LgX92V"},"source":["## Wstęp\n","Jak pewnie słyszałaś/eś, sieci neuronowe są świetnym narzędziem do klasyfikacji obiektów, rozpoznawania złożonych zależności czy przewidywania przyszłych wartości na podstawie historycznych danych. Okazuje się, że są one przy tym podatne na ataki, które mogą znacząco osłabić ich działanie. Ataki te polegają na znalezieniu luki w rozumowaniu modelu. Załóżmy, że sieć nauczyła się rozpoznawać rower na zdjęciu. Spróbujmy inteligentnie zmodyfikować wybrane piksele z obszaru przedstawiającego rower tak, aby \"gołym okiem\" obrazek nadal przedstawiał rower. Zapytajmy sieć neuronową, czy nadal \"widzi\" rower na tak zmodyfikowanym obrazku. Jeżeli model nie zaklasyfikuje już obiektu jako rower, wówczas można stwierdzić, że **atak adwersarialny** się powiódł. **Atakiem adwersarialnym** nazywamy takie spreparowanie danych wejściowych, aby jak najskuteczniej zmylić sieć podczas podejmowania przez nią decyzji."]},{"cell_type":"markdown","metadata":{"id":"ORIU9EFLX92X"},"source":["## Zadanie\n","Zaproponuj metodę włamania się do sieci neuronowej (ataku adwersarialnego), by obniżyć prawdopodobieństwo przypisania próbki do właściwej klasy, przy możliwie małych modyfikacjach testowanych obrazów.\n","\n","Naszym kryterium będzie iloczyn wartości `structural similarity index` ([SSIM](https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html)) uśrednionego po wszystkich obrazach biorących udział w ataku, z wartością różnicy pomiędzy początkową dokładnością modelu na danym zbiorze, a jego dokładnością na tym samym zbiorze poddanym modyfikacjom, zgodnie ze wzorem:  \n","$$SSIM \\cdot (base_{acc} - final_{acc})$$\n","gdzie:\n","- $base_{acc}$ jest dokładnością klasyfikacji modelu na niezmodyfikowanym zbiorze testowym;\n","- $final_{acc}$ jest dokładnością klasyfikacji modelu na zmodyfikowanym zbiorze.\n","\n","Powyższe kryterium i wszystkie wymagane do niego funkcje są zaimplementowane poniżej przez nas."]},{"cell_type":"markdown","metadata":{"id":"nlw0EoHlX92X"},"source":["## Ograniczenia\n","- Twoje finalne rozwiązanie będzie testowane w środowisku z GPU.\n","- Rozpatrywane będą wyłącznie rozwiązania, w których maksymalna odległość między pikselami oryginalnego obrazu a odpowiadającymi im pikselami po ataku adwersarialnym (w sensie wartości bezwzględnej) nie będzie większa niż $0.3$. Obrazy po atakach porównywane są do oryginalnych obrazów znormalizowanych do przedziału $<-1, 1>$.         \n","  **PRZYKŁAD:** Wektory $[-1.0, 0.2, 0.5, -0.3]$ oraz $[-0.9, 0.1, 0.8, 0.0]$ są poprawne, ponieważ wektor różnic bezwzględnych pomiędzy nimi $[0.1, 0.1, 0.3, 0.3]$ nie zawiera elementów większych niż $0.3$. Natomiast wektory $[0.2, 0.5, -1.0, -0.4]$ oraz $[0.3, -0.9, -0.9, -0.6]$ już nie są poprawne, ponieważ drugie elementy obu wektorów różnią się od siebie o $1.4 > 0.3$.\n","- Funkcja `perturbe_dataset()` ma przyjmować trójwymiarową tablicę typu Numpy o rozmiarze (liczba próbek x 28 x 28) i zwracać tablicę typu Numpy o rozmiarze (liczba próbek x 28 x 28), która będzie zbiorem po modyfikacji. Podczas tworzenia zmodyfikowanej wersji zbioru danych można korzystać z wszelkich informacji pochodzących z wytrenowanego modelu.\n","- Twój atak powinien zostać przeprowadzony w maksymalnie 5 minut używając Google Colab z GPU.\n"]},{"cell_type":"markdown","metadata":{"id":"Yv3WWln2X92Y"},"source":["## Uwagi i wskazówki\n","- Model został wytrenowany na zbiorze, w którym każdy z obrazów został z osobna znormalizowany do przedziału $<-1, 1>$, zarówno w zbiorze treningowym jak i walidacyjnym. Zbiór testowy, który nie jest dołączony do instrukcji zadania, będzie znormalizowany w analogiczny sposób.\n","- Każdy obraz zbioru testowego będzie finalnie normalizowany do zakresu $<-1, 1>$, ale obrazy po modyfikacji, czyli na wyjściu funkcji `perturbe_dataset()`, będą jedynie przekształcane do postaci tensora i nie będą poddawane normalizacji.\n","- Swoje rozwiązania możesz testować na zbiorze treningowym i walidacyjnym, ale punktacja za zadanie zostanie przyznana jedynie na podstawie wyniku na zbiorze testowym."]},{"cell_type":"markdown","metadata":{"id":"ELp-ORYTX92Z"},"source":["## Pliki zgłoszeniowe\n"," Tylko ten notebook."]},{"cell_type":"markdown","metadata":{"id":"iMf_J9e8X92Z"},"source":["## Ewaluacja\n","Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` będziesz mógł upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n","\n","Za to zadanie możesz zdobyć pomiędzy 0 i 1 punktów. Zdobędziesz 0 punktów jeśli wartość kryterium na zbiorze testowym wyniesie poniżej 36.0, a 1 punkt jeśli wyniesie powyżej 42.0. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością kryterium."]},{"cell_type":"markdown","metadata":{"id":"qD38dhOgX92Z"},"source":["# Kod startowy"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"gKCnDDkxX92a","executionInfo":{"status":"ok","timestamp":1715846059938,"user_tz":-120,"elapsed":297,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n","FINAL_EVALUATION_MODE = False\n","# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n","# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"X3pGyqgBn3uX","executionInfo":{"status":"ok","timestamp":1715846068460,"user_tz":-120,"elapsed":8162,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","import os\n","from copy import deepcopy\n","\n","import gdown\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from PIL import Image\n","from skimage.metrics import structural_similarity as ssim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms"]},{"cell_type":"markdown","metadata":{"id":"Wv_dRTUkX92c"},"source":["## Ładowanie danych"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBjk-NpbX92c","executionInfo":{"status":"ok","timestamp":1715846091160,"user_tz":-120,"elapsed":20495,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}},"outputId":"7f4569f8-2dd7-4f43-db91-1c79ecb7c0b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Retrieving folder contents\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 1QaZYqish4Us70fqQbhY3a7glec5Vbn5W contest_train_labels.npy\n","Processing file 1pS8J8KHqkGUABFKTSQfzrJujG7iDKB_o contest_train_samples.npy\n","Processing file 1SeBJUJlxEJ3Dgmm-rD2uPMKPXqarRjH_ contest_validation_labels.npy\n","Processing file 15s7KOfwLLsXoUgktOUXfzxOSnvSf_69A contest_validation_samples.npy\n","Retrieving folder 1ULqbHDn2lfmoM0jWY6Zrq0FFMCfZPq9d example_data\n","Processing file 1BAc2nYk0FzzGs_5U0vL_gff4RElZ9Rl8 example_image_1.jpg\n","Processing file 1bCFg2T8nasvZMPS8bw3hTIwmNdoG8-yn example_image_2.jpg\n","Processing file 1mbEtOo0lk0as5p8chiosRtN3Uw8S9dai example_image_3.jpg\n","Processing file 1L4WgIOeWHU_n2Xcr6WDMUqcN8aioSd7J example_image_4.jpg\n","Processing file 1Ql6-9VCIolioxAkdMm8DRZVXRQ32QuXE example_image_5.jpg\n","Processing file 1KjzNegiWR5ZAQaoBhYr72j5hSEyVoub- example_image_6.jpg\n","Processing file 1lR8tU2_044f5q_FeJLRh17JWnK3o73qW example_image_7.jpg\n"]},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents completed\n","Building directory structure\n","Building directory structure completed\n","Downloading...\n","From: https://drive.google.com/uc?id=1QaZYqish4Us70fqQbhY3a7glec5Vbn5W\n","To: /content/data/contest_train_labels.npy\n","100%|██████████| 488k/488k [00:00<00:00, 98.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1pS8J8KHqkGUABFKTSQfzrJujG7iDKB_o\n","To: /content/data/contest_train_samples.npy\n","100%|██████████| 47.8M/47.8M [00:00<00:00, 118MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1SeBJUJlxEJ3Dgmm-rD2uPMKPXqarRjH_\n","To: /content/data/contest_validation_labels.npy\n","100%|██████████| 88.1k/88.1k [00:00<00:00, 69.9MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=15s7KOfwLLsXoUgktOUXfzxOSnvSf_69A\n","To: /content/data/contest_validation_samples.npy\n","100%|██████████| 8.62M/8.62M [00:00<00:00, 55.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1BAc2nYk0FzzGs_5U0vL_gff4RElZ9Rl8\n","To: /content/data/example_data/example_image_1.jpg\n","100%|██████████| 5.12k/5.12k [00:00<00:00, 13.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1bCFg2T8nasvZMPS8bw3hTIwmNdoG8-yn\n","To: /content/data/example_data/example_image_2.jpg\n","100%|██████████| 9.17k/9.17k [00:00<00:00, 20.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1mbEtOo0lk0as5p8chiosRtN3Uw8S9dai\n","To: /content/data/example_data/example_image_3.jpg\n","100%|██████████| 6.16k/6.16k [00:00<00:00, 14.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1L4WgIOeWHU_n2Xcr6WDMUqcN8aioSd7J\n","To: /content/data/example_data/example_image_4.jpg\n","100%|██████████| 5.70k/5.70k [00:00<00:00, 14.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Ql6-9VCIolioxAkdMm8DRZVXRQ32QuXE\n","To: /content/data/example_data/example_image_5.jpg\n","100%|██████████| 7.17k/7.17k [00:00<00:00, 18.4MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1KjzNegiWR5ZAQaoBhYr72j5hSEyVoub-\n","To: /content/data/example_data/example_image_6.jpg\n","100%|██████████| 6.71k/6.71k [00:00<00:00, 16.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1lR8tU2_044f5q_FeJLRh17JWnK3o73qW\n","To: /content/data/example_data/example_image_7.jpg\n","100%|██████████| 7.19k/7.19k [00:00<00:00, 19.0MB/s]\n","Download completed\n"]}],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","if not FINAL_EVALUATION_MODE:\n","    if not os.path.exists(f\"data\"):\n","        gdown.download_folder(url=\"https://drive.google.com/drive/folders/1qmRd5O-LdOki1-HC4dgfaNrstzG3h_cN?usp=sharing\", output=f\"./data\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"82Xd6qYBX92d","executionInfo":{"status":"ok","timestamp":1715846180742,"user_tz":-120,"elapsed":278,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","# Klasa zbioru danych\n","class ContestDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        x = Image.fromarray(self.data[index])\n","        if self.transform:\n","            x = self.transform(x)\n","        y = self.labels[index]\n","        return x, y"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hqGgvnokX92d","executionInfo":{"status":"ok","timestamp":1715846182407,"user_tz":-120,"elapsed":386,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","# Funkcja do normalizacji wartości pikseli do przedziału <-1, 1>\n","def normalize_samples(samples):\n","    assert len(samples.shape) == 3\n","    samples = samples.reshape(-1, 28 * 28)\n","    minimum_values = np.min(samples, axis=1)\n","    maximum_values = np.max(samples, axis=1)\n","\n","    normalized_samples = (2 * (samples - minimum_values[:, np.newaxis]) / \\\n","                          (maximum_values - minimum_values)[:, np.newaxis]) - 1\n","\n","    normalized_samples = normalized_samples.reshape(\n","        normalized_samples.shape[0], 28, 28\n","    )\n","    return normalized_samples"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"2Kr_DLGEX92e","executionInfo":{"status":"ok","timestamp":1715846812082,"user_tz":-120,"elapsed":928,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","# Wczytajmy potrzebne dane\n","# X_train oraz y_train posłużą Ci do przygotowania ataku adwersarialnego\n","# Na X_validation oraz y_validation sprawdzisz czy Twoje rozwiązanie przechodzi skrypt ewaluacyjny\n","path_to_data = './data/'\n","\n","X_train = np.load(f'{path_to_data}contest_train_samples.npy') / 255.\n","y_train = np.load(f'{path_to_data}contest_train_labels.npy')\n","X_validation = np.load(f'{path_to_data}contest_validation_samples.npy') / 255.\n","y_validation = np.load(f'{path_to_data}contest_validation_labels.npy')\n","\n","X_train = normalize_samples(X_train)\n","X_validation = normalize_samples(X_validation)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-hj8Y3z4X92e","executionInfo":{"status":"ok","timestamp":1715846191157,"user_tz":-120,"elapsed":292,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","validation_set = ContestDataset(X_validation,\n","                                y_validation,\n","                                transform=transforms.ToTensor())\n","validation_loader = DataLoader(validation_set,\n","                                batch_size=1,\n","                                shuffle=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HI3Wo6SKoDpr","executionInfo":{"status":"ok","timestamp":1715846241526,"user_tz":-120,"elapsed":298,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}}},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","# Definicja klasyfikatora, który chcemy oszukać!\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.fc1 = nn.Linear(64 * 11 * 11, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.pool(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"i-OtT37HX92f","executionInfo":{"status":"error","timestamp":1715847191935,"user_tz":-120,"elapsed":470,"user":{"displayName":"lewy 700","userId":"06061034898661850654"}},"outputId":"51ec0216-6f2a-438f-eadc-864e725fc624"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"PytorchStreamReader failed reading zip archive: failed finding central directory","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-dbe1f3e7a47a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Wczytajmy pretrenowane wagi do naszego modelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m net.load_state_dict(torch.load('trained_model.pth',\n\u001b[0m\u001b[1;32m     12\u001b[0m                                map_location=device))\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"]}],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","\n","# Stwórzmy nasz klasyfikator\n","net = Net()\n","\n","# Wczytajmy pretrenowane wagi do naszego modelu\n","net.load_state_dict(torch.load('trained_model.pth',\n","                               map_location=device))"]},{"cell_type":"markdown","metadata":{"id":"UyTlnaXeX92g"},"source":["## Kod z kryteriami oceniającymi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37lOCnKHX92g"},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","def evaluate_network(data_loader,\n","                     model,\n","                     device,\n","                     verbose=True):\n","    # Dokonajmy ewaluacji wytrenowanego modelu na wybranym zbiorze\n","    all_predictions, all_labels = [], []\n","    model.to(device)\n","    # Sieć neuronowa musi zostać przeniesiona do trybu ewaluacji\n","    model.eval()\n","    with torch.no_grad():\n","        for data in data_loader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            # Wybieramy klasę o najwyższym prawdopodobieństwie przynależności\n","            _, predicted = torch.max(outputs.data, 1)\n","            all_predictions.append(predicted.ravel())\n","            all_labels.append(labels.ravel())\n","    all_predictions = torch.cat(all_predictions, dim=0)\n","    all_labels = torch.cat(all_labels, dim=0)\n","    # Sprawdzamy, ile etykiet zostało prawidłowo wytypowanych przez sieć\n","    correct = (all_predictions == all_labels).sum().item()\n","    accuracy = (100 * correct / all_labels.size()[0])\n","    no_of_elements = len(data_loader.dataset)\n","    if verbose:\n","        print(f'Dokładność klasyfikacji na {no_of_elements} obrazów wybranego zbioru wynosi '\n","              f'{accuracy} %.')\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxx8AaUuX92h"},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","\n","# Funkcja do wyliczenia SSIM oraz maksymalnej odległości między odpowiadającymi pikselami\n","def calculate_similarity(original_dataset,\n","                         perturbed_dataset):\n","    # Zarówno original_dataset jak i perturbed_dataset mają być typu Numpy array.\n","    # Mają mieć taki sam rozmiar, tj. (liczba elementów x 28 x 28)\n","    assert original_dataset.shape == perturbed_dataset.shape\n","    assert original_dataset.shape[1] == original_dataset.shape[2] == 28\n","    assert perturbed_dataset.shape[1] == perturbed_dataset.shape[2] == 28\n","    similarities, L1_distances = [], []\n","    for i in range(original_dataset.shape[0]):\n","        original_element = original_dataset[i].ravel()\n","        perturbed_element = perturbed_dataset[i].ravel()\n","        similarities.append(\n","            ssim(\n","                original_element,\n","                perturbed_element,\n","                data_range=2)\n","            )\n","        L1_distances.append(\n","            np.max(np.abs(\n","                original_element - perturbed_element\n","            ))\n","        )\n","    mean_SSIM = np.mean(similarities)\n","    max_distance = np.max(L1_distances)\n","    print(f'Średnia wartość SSIM wynosi {mean_SSIM}, a największa odległość między pikselami wynosi: {max_distance}.')\n","    return mean_SSIM, max_distance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F75JjuauX92i"},"outputs":[],"source":["######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n","if not FINAL_EVALUATION_MODE:\n","    result = evaluate_network(\n","        validation_loader,\n","        net,\n","        device,\n","        verbose=True\n","    )"]},{"cell_type":"markdown","metadata":{"id":"-ysJx6LoX92i"},"source":["# Twoje rozwiązanie"]},{"cell_type":"markdown","metadata":{"id":"N3hJVHBqX92i"},"source":["To jest jedyna sekcja, w której musisz coś zrobić."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMvfkZOUZzPj"},"outputs":[],"source":["def perturbe_dataset(original_dataset):\n","    \"\"\"\n","    To tutaj masz przygotować funkcję do zaburzania zbioru danych. Na wejściu ma znajdować\n","    się tablica typu Numpy array o rozmiarze (liczba elementów, 28, 28). Podobnie ma być na\n","    wyjściu. A co wydarzy się po drodze? To już zależy od Ciebie i Twojej pomysłowości!\n","    \"\"\"\n","    assert len(original_dataset.shape) == 3\n","    # TODO:\n","    perturbed_dataset = deepcopy(original_dataset)\n","    assert len(perturbed_dataset.shape) == 3\n","    assert perturbed_dataset.shape[1] == 28\n","    assert perturbed_dataset.shape[2] == 28\n","    return perturbed_dataset"]},{"cell_type":"markdown","metadata":{"id":"XuhritGaX92j"},"source":["# Ewaluacja"]},{"cell_type":"markdown","metadata":{"id":"gENLjwRoX92j"},"source":["Poniższy kod będzie służył ewaluacji rozwiązania. Po wysłaniu rozwiązania do nas zostanie wykonana funkcja `evaluate_algorithm(net, X_validation, y_validation, device, perturbe_dataset)`, t.j. prawie identyczny kod jak niżej będzie się uruchamiał na katalogu zdjęć `test_data` dostępnym tylko dla sprawdzających zadania.\n","\n","Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snHoevXtX92j"},"outputs":[],"source":["def evaluate_algorithm(model, images, labels, device, perturbe_algorithm):\n","    dataset_for_perturbation = deepcopy(images)\n","    dataset_attacked = perturbe_algorithm(dataset_for_perturbation)\n","\n","    SSIM, distance = calculate_similarity(\n","        dataset_for_perturbation,\n","        dataset_attacked\n","    )\n","    assert distance <= 0.3\n","\n","    perturbed_set = ContestDataset(dataset_attacked,\n","                                labels,\n","                                transform=transforms.ToTensor())\n","    perturbed_loader = DataLoader(perturbed_set,\n","                                batch_size=64,\n","                                shuffle=False)\n","    perturbed_accuracy = evaluate_network(\n","        perturbed_loader,\n","        model,\n","        device,\n","        verbose=True\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qTyltqWYX92k"},"outputs":[],"source":["if not FINAL_EVALUATION_MODE:\n","    evaluate_algorithm(net, X_validation, y_validation, device, perturbe_dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}