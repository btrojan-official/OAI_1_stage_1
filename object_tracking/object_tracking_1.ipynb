{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2szhiq0QJ4Ek"
      },
      "source": [
        "# Śledzenie obiektów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://i.imgur.com/wKXXFkQ.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wstęp\n",
        "W erze cyfrowej, w obliczu rosnącej lawinowo ilości danych wideo, zdolność do ich automatycznego rozpoznawania i interpretowania staje się kluczowa w wielu dziedzinach – od bezpieczeństwa publicznego po autonomiczne pojazdy. Technologie oparte na głębokim uczeniu rewolucjonizują sposób, w jaki przetwarzamy informacje wizualne. Kluczowym wyzwaniem jest tu detekcja i śledzenie obiektów na filmach wideo.\n",
        "\n",
        "Celem tego zadania jest opracowanie algorytmu, który będzie w stanie analizować sekwencje ruchów w grze \"trzy kubki\". Uczestnicy mają za zadanie określić końcową pozycję kubków po serii ruchów, korzystając z analizy statycznych obrazów z każdej klatki nagrania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "# Poniższe funkcje ułatwiają pracę z dostarczonymi danymi\n",
        "# W kolejnych komórkach zobaczysz przykłady ich użycia\n",
        "from utils.utils import get_level_info, get_video_data, display_video, download_and_replace_data\n",
        "\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    images, coordinates, target, path_to_images = get_video_data(level=1,video_id=0,dataset=\"example\")\n",
        "    display_video(images,rescale=0.7,FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4Rs-ZqfMfG"
      },
      "source": [
        "## Zadanie 1: Gra w trzy kubki\n",
        "\n",
        "Jedną z możliwości podejścia do problemu rozpoznawania obiektów na wideo jest zastosowanie modelu dedykowanego do analizy statycznych obrazów dla każdej z klatek. To właśnie będziemy starali się tutaj osiągnąć. Dla każdej klatki w animacjach dostarczyliśmy przewidziany przez model opis tego, w których miejscach znajdują się kubki. Na nagraniach pokazane jest jak są zamieniane miejscami. Twoim zadaniem będzie określenie pozycji, na którą finalnie trafią. Oznaczymy ustawienie początkowe jako $[0,1,2]$ licząc w kolejności od lewej do prawej (po współrzędej `x`). Jeżeli następnie przestawimy pierwszy od lewej kubek na przeciwległy koniec, uzyskamy $[1,2,0]$.\n",
        "\n",
        "Będziesz miał dostęp zarówno do wszystkich klatek animacji, jak i do oznaczonych przez nas prostokątów ograniczających, w których znajdują się kubki. Co ważne, algorytm, który będziesz tworzył ma korzystać jedynie z informacji o prostokątach ograniczających. W tym zadaniu, klatki wideo są dostarczone jedynie do wizualizacji przykładów i algorytmu, na własne potrzeby.\n",
        "\n",
        "Punkty za to zadanie będą przyznane za osiągnięcie jak najdokładniejszych predykcji na zbiorze testowym. Kryterium będzie *accuracy*. Ewaluacja na zbiorze testowym będzie dokonana przez organizatorów.\n",
        "\n",
        "## Pliki zgłoszeniowe\n",
        "Tylko ten notebook zawierający **kod** oraz **krótki raport** opisujący Twoje rozwiązanie (do 300 słów). Miejsce na raport znajdziesz na końcu tego notebooka.\n",
        "\n",
        "## Ograniczenia\n",
        "- Twoja funkcja powinna zwracać predykcje w maksymalnie 5 minut używając Google Colab bez GPU.\n",
        "\n",
        "## Uwagi i wskazówki\n",
        "- Testuj swoje rozwiązanie na zbiorze plików wideo `level_1`.\n",
        "- **Skuteczność modelu**: przetestuj skuteczność modelu na zbiorze walidacyjnym używając dostarczonej przez nas funkcji **submission_script**, umieść ten wynik w raporcie.\n",
        "\n",
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` możesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n",
        "\n",
        "Za to podzadanie możesz zdobyć pomiędzy 0 i 0.5 punktów. Zdobędziesz 0 punktów jeśli Twoje accuracy na zbiorze testowym będzie poniżej 50%. Jeśli będzie równe 100%, otrzymasz 0.5 punktu. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością metryki."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Poniższe biblioteki są wystarczające do wykonania wszystkich zadań\n",
        "# Jeśli jednak chcesz użyć innych, sprawdź czy są dostępne na serwerze (requirements.txt)\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import IPython.display\n",
        "import json\n",
        "import PIL\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not FINAL_EVALUATION_MODE:\n",
        "    # Funkcja pomocnicza do ładowania danych\n",
        "    images, _, _, _ = get_video_data(level=1,video_id=0,dataset=\"example\")\n",
        "\n",
        "    with open(os.path.join(os.getcwd(),'example_tracks','tracks_1_0.json'), 'r') as f:\n",
        "        tracks = json.load(f)\n",
        "\n",
        "    for key in tracks.keys():\n",
        "        tracks[key] = [tuple(el) for el in tracks[key]]\n",
        "\n",
        "    # Funkcja pomocnicza do wyświetlania danych\n",
        "    display_video(images,\n",
        "                    tracks=tracks,\n",
        "                    rescale=0.7,\n",
        "                    FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pobieranie danych do podzadań 1, 2 i 3 (około ~646Mb), skrypt będzie wykonywał się parę minut\n",
        "# Wystarczy, że pobierzesz dane tylko raz. Na serwerze sprawdzającym dane będą już pobrane\n",
        "# Struktura plików będzie identyczna jak tutaj\n",
        "# if not FINAL_EVALUATION_MODE:\n",
        "#     download_and_replace_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Funkcja pomocnicza do testowania algorytmu\n",
        "def submission_script(algorithm,level,verbose=False,dataset=\"valid\"):\n",
        "    num_videos, _ = get_level_info(level=level,dataset=dataset)\n",
        "    correct = []\n",
        "    exception_messages = set()\n",
        "    for video_number in range(num_videos):\n",
        "        _, coordinates, target, _ = get_video_data(level=level,video_id=video_number,dataset=dataset)\n",
        "        try:\n",
        "            prediction = algorithm(coordinates)\n",
        "            if tuple(target) == tuple(prediction):\n",
        "                correct.append(1)\n",
        "            else:\n",
        "                correct.append(0)\n",
        "            if verbose:\n",
        "                print(f\"Video: animation_{str(video_number).zfill(4)}\")\n",
        "                print(f\"Prediction: {prediction}\")\n",
        "                print(f\"Target:     {target}\")\n",
        "                print(f\"Score: {tuple(target) == tuple(prediction)}\", end='\\n\\n')\n",
        "                # break\n",
        "        except Exception as e:\n",
        "            correct.append(0)\n",
        "            exception_messages.add(str(e))\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {np.mean(correct)}\")\n",
        "        print(f\"Correctness: {correct}\")\n",
        "    return np.sum(correct) / num_videos, correct, exception_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def your_algorithm_task_1(coordinates): # nie zmieniaj nazwy funkcji\n",
        "    def get_order(frame):\n",
        "        frame = np.array(frame)\n",
        "\n",
        "        if frame[0,0] > frame[1,0] and frame[1,0] > frame[2,0]:\n",
        "            return [2,1,0]\n",
        "        elif frame[1,0] > frame[0,0] and frame[0,0] > frame[2,0]:\n",
        "            return [1,2,0]\n",
        "        elif frame[0,0] > frame[2,0] and frame[2,0] > frame[1,0]:\n",
        "            return [2,0,1]\n",
        "        elif frame[1,0] > frame[2,0] and frame[2,0] > frame[0,0]:\n",
        "            return [0,2,1]\n",
        "        elif frame[2,0] > frame[0,0] and frame[0,0] > frame[1,0]:\n",
        "            return [1,0,2]\n",
        "        elif frame[2,0] > frame[1,0] and frame[1,0] > frame[0,0]:\n",
        "            return [0,1,2]\n",
        "\n",
        "    def distance(obj1, obj2):\n",
        "        a = (((obj1[0]-obj2[0])**2) + ((obj1[1]-obj2[1])**2))**0.5\n",
        "        b = (((obj1[2]-obj2[2])**2) + ((obj1[3]-obj2[3])**2))**0.5\n",
        "        return (a+b)/2\n",
        "\n",
        "    def move(frame, prev_frame, order):\n",
        "        output = np.zeros(3)\n",
        "        distances_matrix = np.zeros((3,3))\n",
        "        \n",
        "        for i in range(len(frame)):\n",
        "            for j in range(len(prev_frame)):\n",
        "                distances_matrix[i,j] = distance(frame[i], prev_frame[j])\n",
        "\n",
        "        for _ in range(3):\n",
        "            flat_min = np.argmin(distances_matrix)\n",
        "            idx = np.unravel_index(flat_min, distances_matrix.shape)\n",
        "\n",
        "            output[idx[0]] = order[idx[1]]\n",
        "\n",
        "            distances_matrix[idx[0],:] = np.inf\n",
        "            distances_matrix[:,idx[1]] = np.inf\n",
        "        return output   \n",
        "\n",
        "    current_order = get_order(coordinates[\"frame_0000.png\"])\n",
        "    prev_frame = coordinates[\"frame_0000.png\"]\n",
        "\n",
        "    for frame in coordinates.keys():\n",
        "        current_order = move(coordinates[frame], prev_frame, current_order)\n",
        "        prev_frame = coordinates[frame]\n",
        "\n",
        "    final_order = get_order(prev_frame)\n",
        "\n",
        "    end = np.zeros(3)\n",
        "    for i in range(len(final_order)):\n",
        "        end[final_order[i]] = current_order[i]\n",
        "    \n",
        "    return list(end.astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video: animation_0000\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0001\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0002\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0003\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0004\n",
            "Prediction: [0, 1, 2]\n",
            "Target:     [0, 1, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0005\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0006\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0007\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0008\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0009\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0010\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0011\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0012\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0013\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0014\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0015\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0016\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0017\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0018\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0019\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0020\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0021\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0022\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0023\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0024\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0025\n",
            "Prediction: [0, 1, 2]\n",
            "Target:     [0, 1, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0026\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0027\n",
            "Prediction: [0, 1, 2]\n",
            "Target:     [0, 1, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0028\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0029\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0030\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0031\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0032\n",
            "Prediction: [0, 1, 2]\n",
            "Target:     [0, 1, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0033\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0034\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0035\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0036\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0037\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0038\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0039\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0040\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0041\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0042\n",
            "Prediction: [0, 2, 1]\n",
            "Target:     [0, 2, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0043\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0044\n",
            "Prediction: [2, 1, 0]\n",
            "Target:     [2, 1, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0045\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0046\n",
            "Prediction: [1, 2, 0]\n",
            "Target:     [1, 2, 0]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0047\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0048\n",
            "Prediction: [2, 0, 1]\n",
            "Target:     [2, 0, 1]\n",
            "Score: True\n",
            "\n",
            "Video: animation_0049\n",
            "Prediction: [1, 0, 2]\n",
            "Target:     [1, 0, 2]\n",
            "Score: True\n",
            "\n",
            "Accuracy: 1.0\n",
            "Correctness: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "if not FINAL_EVALUATION_MODE:\n",
        "    # Sprawdź jak działa Twój algorytm\n",
        "    accuracy, correctness, _ = submission_script(\n",
        "        algorithm=your_algorithm_task_1,\n",
        "        level=1,\n",
        "        verbose=True,\n",
        "        dataset=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zapisz swój raport do zmiennej poniżej, abyśmy mogli go później automatycznie odczytać sprawdzaczką\n",
        "raport_1 = \\\n",
        "\"\"\"\n",
        "Raport z zadania:\n",
        "1. Ze względu na to, ze kolejność ograniczników w zmiennej 'coordinates' jest losowa napisałem funkcję 'get_order' która zwraca kolejność kubeczków na podstawie lewego górnego narożnika.\n",
        "Wywołuję tą funkcję na początku by wiedzieć które współrzędne dotyczą którego kubeczka i oznaczam je w tablicy dla pierwszej klatki. \n",
        "2. Potem iteruję się przez kolejne klatki wideo i wywołuję dla nich funkcję 'move', która na podstawie poprzedniej klatki oraz tego które współrzędne poprzedniej klatki odnosiły się do\n",
        "którego kubeczka (kubeczki są oznaczone jako [0, 1, 2] na podstawie ich pozycji startowej wyliczonej przez funkcję 'get_order') liczy które współrzędne bierzącej klatki odnoszą się do\n",
        "którego kubeczka zgodnie z oznaczeniami z poprzedniej klatki.\n",
        "Robi to poprzez wyliczenie macierzy ('distances_matrix') odelgłości pomiędzy ogranicznikami z poprzedniej klatki, a ogranicznikami z następnej klatki (funkcja 'get_distances')\n",
        "i przyporządkowaniu każdemu ogranicznikowi z bierzącej klatki najbliższy mu ogranicznik z poprzedniej.\n",
        "3. Po przejściu przez wszystkie klatki zmienna 'current_order' przechowuje dane które wspołrzędne ostatniej klatki odnoszą się do którego kubeczka, więc wystarczy użyć na tych współrzędnych\n",
        "funkcji 'get_order' i przypisać pozycje zwrócone do tych startowych i otrzymujemy wynik.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
